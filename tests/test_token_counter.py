import pytest
from app.services.token_counter import TokenCounter

@pytest.fixture
def token_counter_service():
    return TokenCounter()

def test_token_counting():
    """Test that token counting works correctly for different inputs."""
    service = TokenCounter()
    
    # Test with a simple string
    result = service.count_tokens("Hello world!", "gpt-3.5-turbo")
    assert result["token_count"] == 3
    assert result["model"] == "gpt-3.5-turbo"
    assert "processing_time_ms" in result
    
    # Test with a longer string
    result = service.count_tokens("This is a longer piece of text that should have more tokens.", "gpt-3.5-turbo")
    assert result["token_count"] > 5
    
    # Test with a different model
    result = service.count_tokens("Hello world!", "gpt-4")
    assert result["model"] == "gpt-4"

def test_batch_token_counting():
    """Test that batch token counting works correctly."""
    service = TokenCounter()
    
    texts = [
        {"text": "Hello world!", "text_id": "text1"},
        {"text": "This is another example.", "text_id": "text2"}
    ]
    
    results = service.batch_count_tokens(texts, "gpt-3.5-turbo")
    
    assert len(results) == 2
    assert results[0]["text_id"] == "text1"
    assert results[0]["token_count"] == 3
    assert results[1]["text_id"] == "text2"
    assert results[1]["token_count"] > 3

def test_model_selection():
    """Test that different models work correctly."""
    service = TokenCounter()
    
    # All these models should work and potentially give different results
    models = ["gpt-3.5-turbo", "gpt-4", "text-davinci-003"]
    
    for model in models:
        result = service.count_tokens("Hello world!", model)
        assert result["model"] == model

# Generated by Copilot
