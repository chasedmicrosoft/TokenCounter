import time
import tiktoken
from typing import Dict, List, Union
import logging

from app.core.config import get_settings, is_dev_mode

logger = logging.getLogger(__name__)

class TokenCounter:
    """Service for counting tokens in text."""
    
    def __init__(self):
        self.settings = get_settings()
        self._encoders = {}  # Cache for tokenizers
    
    def get_encoder(self, model: str):
        """Get the appropriate tokenizer for a given model."""
        if model not in self._encoders:
            try:
                if model in ["gpt-3.5-turbo", "gpt-4"]:
                    # These models use cl100k_base encoding
                    self._encoders[model] = tiktoken.get_encoding("cl100k_base")
                elif model == "text-davinci-003":
                    self._encoders[model] = tiktoken.encoding_for_model("text-davinci-003")
                else:
                    # Default fallback
                    self._encoders[model] = tiktoken.get_encoding("cl100k_base")
            except Exception as e:
                logger.error(f"Error loading encoder for model {model}: {str(e)}")
                # Fallback to a default encoder
                self._encoders[model] = tiktoken.get_encoding("cl100k_base")
        
        return self._encoders[model]
    
    def count_tokens(self, text: str, model: str = None) -> Dict:
        """
        Count tokens in the provided text.
        
        Args:
            text: The input text to count tokens in
            model: The model to use for tokenization (default: from settings)
            
        Returns:
            Dict with token count and metadata
        """
        start_time = time.time()
        
        if model is None:
            model = self.settings.DEFAULT_MODEL
        
        # For development mode, we could return mock data
        if is_dev_mode() and text == "__MOCK_TEST__":
            return {
                "token_count": 42,
                "model": model,
                "processing_time_ms": 1
            }
        
        # Get the appropriate encoder for this model
        encoder = self.get_encoder(model)
        
        # Encode and count tokens
        tokens = encoder.encode(text)
        token_count = len(tokens)
        
        # Calculate processing time
        end_time = time.time()
        processing_time_ms = int((end_time - start_time) * 1000)
        
        return {
            "token_count": token_count,
            "model": model,
            "processing_time_ms": processing_time_ms
        }
    
    def batch_count_tokens(self, texts: List[Dict], model: str = None) -> List[Dict]:
        """
        Count tokens for multiple text inputs.
        
        Args:
            texts: List of dictionaries with text and optional text_id
            model: Model to use for tokenization (default: from settings)
            
        Returns:
            List of dictionaries with token counts and metadata
        """
        results = []
        
        for item in texts:
            text = item["text"]
            text_id = item.get("text_id")
            
            result = self.count_tokens(text, model)
            
            if text_id:
                result["text_id"] = text_id
                
            results.append(result)
            
        return results

# Singleton instance
token_counter = TokenCounter()

# Generated by Copilot
